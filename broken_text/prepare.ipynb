{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from butter_fingers import _butter_finger\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "from multiprocessing.dummy import Pool as ThreadPool\n",
    "import elasticsearch\n",
    "from pydantic import BaseModel\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"../.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TyposResponse(BaseModel):\n",
    "    text_with_typos: str\n",
    "    \n",
    "PROMPT = \"Wprowadź do tekstu jakieś częste literówki: `{text}`\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def introduce_typos(text):\n",
    "    client = OpenAI()\n",
    "    response = client.responses.parse(\n",
    "        input=PROMPT.format(text=text),\n",
    "        model=\"gpt-4o-mini\",\n",
    "        temperature=0.0,\n",
    "        text_format=TyposResponse,\n",
    "    )\n",
    "    return response.output_parsed.text_with_typos\n",
    "\n",
    "def butter_finger(text):\n",
    "    return _butter_finger(text, prob=0.1, keyboard=\"qwerty\", seed=0, max_outputs=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-typos: Dokąd nocą tupta jeż?\n",
      "Butter-fingers: Dokąf nocą tupta jeż?\n"
     ]
    }
   ],
   "source": [
    "print(\"GPT-typos:\", introduce_typos(\"Dokąd nocą tupta jeż?\"))\n",
    "print(\"Butter-fingers:\", butter_finger(\"Dokąd nocą tupta jeż?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = elasticsearch.Elasticsearch(hosts=\"http://localhost:9200\")\n",
    "\n",
    "def sample_documents(index):\n",
    "    res = es.search(index=index, body={\"size\": 20, \"query\": {\"function_score\": {\"random_score\": {}}}})\n",
    "    return res['hits']['hits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import difflib\n",
    "import re\n",
    "\n",
    "def find_typo_corrections(original: str, with_typos: str) -> list[tuple[str, str]]:\n",
    "    \"\"\"Znajduje różnice między tekstem z literówkami a oryginałem - zwraca całe słowa.\"\"\"\n",
    "    corrections = []\n",
    "    \n",
    "    # Dzielimy na słowa\n",
    "    original_words = original.split()\n",
    "    typos_words = with_typos.split()\n",
    "    \n",
    "    # Używamy SequenceMatcher do znalezienia różnic na poziomie słów\n",
    "    matcher = difflib.SequenceMatcher(None, typos_words, original_words)\n",
    "    \n",
    "    for tag, i1, i2, j1, j2 in matcher.get_opcodes():\n",
    "        if tag == 'replace':\n",
    "            # Słowa zostały zamienione\n",
    "            typo_phrase = \" \".join(typos_words[i1:i2])\n",
    "            correct_phrase = \" \".join(original_words[j1:j2])\n",
    "            if typo_phrase and correct_phrase:\n",
    "                corrections.append((typo_phrase, correct_phrase))\n",
    "        elif tag == 'delete':\n",
    "            # Słowa zostały usunięte w with_typos (były dodatkowe)\n",
    "            typo_phrase = \" \".join(typos_words[i1:i2])\n",
    "            if typo_phrase:\n",
    "                corrections.append((typo_phrase, \"\"))\n",
    "        elif tag == 'insert':\n",
    "            # Słowa zostały dodane w oryginale (brakowały w with_typos)\n",
    "            correct_phrase = \" \".join(original_words[j1:j2])\n",
    "            if correct_phrase:\n",
    "                corrections.append((\"\", correct_phrase))\n",
    "    \n",
    "    return corrections\n",
    "\n",
    "\n",
    "def format_thinking_answer(original: str, with_typos: str) -> str:\n",
    "    \"\"\"\n",
    "    Formatuje dane w stylu Deepseek-R1:\n",
    "    <think>\n",
    "    x -> y\n",
    "    a -> b\n",
    "    </think>\n",
    "    <answer>poprawiony tekst</answer>\n",
    "    \"\"\"\n",
    "    corrections = find_typo_corrections(original, with_typos)\n",
    "    \n",
    "    # Budujemy sekcję <think>\n",
    "    think_lines = []\n",
    "    for typo, correct in corrections:\n",
    "        if typo and correct:\n",
    "            think_lines.append(f\"{typo} -> {correct}\")\n",
    "        elif typo:\n",
    "            think_lines.append(f\"usuń: {typo}\")\n",
    "        elif correct:\n",
    "            think_lines.append(f\"dodaj: {correct}\")\n",
    "    \n",
    "    think_section = \"<think>\\\\n\" + \"\\\\n\".join(think_lines) + \"\\\\n</think>\"\n",
    "    answer_section = f\"<answer>{original}</answer>\"\n",
    "    \n",
    "    return f\"{think_section}\\\\n{answer_section}\"\n",
    "\n",
    "\n",
    "def prepare_doc_thinking(doc):\n",
    "    \"\"\"Przygotowuje dokument w formacie SFT z thinking.\"\"\"\n",
    "    text = doc['_source']['text']\n",
    "    random_ceil = min(1000, len(text))\n",
    "    random_begin = np.random.randint(0, len(text) - random_ceil + 1)\n",
    "    original_passage = text[random_begin:random_begin + random_ceil]\n",
    "\n",
    "    # Wprowadzamy literówki\n",
    "    if np.random.rand() <= 0.5:\n",
    "        passage_with_typos = butter_finger(original_passage)\n",
    "    else:\n",
    "        passage_with_typos = introduce_typos(original_passage)\n",
    "\n",
    "    # Formatujemy w stylu thinking/answer\n",
    "    formatted_output = format_thinking_answer(original_passage, passage_with_typos)\n",
    "    \n",
    "    return passage_with_typos, formatted_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Dokąf -> Dokąd\n",
      "</think>\n",
      "<answer>Dokąd nocą tupta jeż?</answer>\n",
      "\n",
      "==================================================\n",
      "\n",
      "<think>\n",
      "jst -> jest\n",
      "tekzt -> tekst\n",
      "wielloma -> wieloma\n",
      "</think>\n",
      "<answer>To jest przykładowy tekst z wieloma słowami.</answer>\n"
     ]
    }
   ],
   "source": [
    "# Test nowej funkcji formatującej\n",
    "original = \"Dokąd nocą tupta jeż?\"\n",
    "with_typos = \"Dokąf nocą tupta jeż?\"\n",
    "\n",
    "result = format_thinking_answer(original, with_typos)\n",
    "print(result)\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Test z dłuższym tekstem\n",
    "original2 = \"To jest przykładowy tekst z wieloma słowami.\"\n",
    "with_typos2 = \"To jst przykładowy tekzt z wielloma słowami.\"\n",
    "result2 = format_thinking_answer(original2, with_typos2)\n",
    "print(result2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_doc(doc):\n",
    "    text = doc['_source']['text']\n",
    "    random_ceil = min(1000, len(text))\n",
    "    random_begin = np.random.randint(0, len(text) - random_ceil+1)\n",
    "    passage = text[random_begin:random_begin+random_ceil]\n",
    "    \n",
    "    # Remove first and last words, as they might be incomplete\n",
    "    passage = passage.split(\" \")[1:-1]\n",
    "    passage = \" \".join(passage)\n",
    "\n",
    "    if np.random.rand() <= 0.5:\n",
    "        transformed = butter_finger(passage)\n",
    "    else:\n",
    "        transformed = introduce_typos(passage)\n",
    "\n",
    "    return passage, transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Thread, Lock\n",
    "import tqdm\n",
    "import csv\n",
    "\n",
    "lock = Lock()\n",
    "\n",
    "def prepare_dataset(dname=\"dataset_train.csv\", prepare_func=prepare_doc):\n",
    "    def _inner(doc):\n",
    "        try:\n",
    "            passage, transformed = prepare_func(doc)\n",
    "\n",
    "            with lock:\n",
    "                with open(dname, \"a\") as f:\n",
    "                    writer = csv.writer(f)\n",
    "                    writer.writerow([\n",
    "                        passage.replace(\"\\n\", \" \"),\n",
    "                        transformed.replace(\"\\n\", \" \"),\n",
    "                    ])\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "    threads = []\n",
    "    documents_judiciary = sample_documents(\"orzeczenia_03_2024_search-giga-index\")\n",
    "    documents_eurlex = sample_documents(\"eurlex_03_2025_search-giga-index\")\n",
    "    documents_acts = sample_documents(\"ustawy_06_2025_search-giga-index\")\n",
    "    documents_eureka = sample_documents(\"eureka_03_2024_search-giga-index\")\n",
    "    docuements_codexes = sample_documents(\"kodeksy_06_2025_search-giga-index\")\n",
    "    documents_kio = sample_documents(\"kio_exam_07_2025_search\")\n",
    "    documents = documents_judiciary + documents_eurlex + documents_acts + documents_eureka + docuements_codexes + documents_kio\n",
    "    for doc in documents:\n",
    "        t = Thread(target=_inner, args=(doc,))\n",
    "        t.start()\n",
    "        threads.append(t)\n",
    "    \n",
    "    for t in threads:\n",
    "        t.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 20/100 [10:48<2:24:05, 108.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 validation error for TyposResponse\n",
      "  Invalid JSON: EOF while parsing a string at line 1 column 45528 [type=json_invalid, input_value='{\"text_with_typos\":\"sied...awczej do Sądu Okręg', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 32/100 [17:39<1:38:15, 86.69s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 validation error for TyposResponse\n",
      "  Invalid JSON: EOF while parsing a string at line 1 column 65345 [type=json_invalid, input_value='{\"text_with_typos\":\"h po...stant to=TyposResponse ', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 34/100 [22:48<2:27:28, 134.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 validation error for TyposResponse\n",
      "  Invalid JSON: EOF while parsing a string at line 1 column 46016 [type=json_invalid, input_value='{\"text_with_typos\":\"g UZ...egradowalne patyczki do', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 48/100 [30:47<1:16:12, 87.93s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 validation error for TyposResponse\n",
      "  Invalid JSON: EOF while parsing a string at line 1 column 44658 [type=json_invalid, input_value='{\"text_with_typos\":\"eina... Sprawiedliwości, art.', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 50/100 [37:02<2:08:18, 153.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 validation error for TyposResponse\n",
      "  Invalid JSON: EOF while parsing a string at line 1 column 49305 [type=json_invalid, input_value='{\"text_with_typos\":\" - I...ku towarowego-Względne', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 81/100 [50:13<33:07, 104.59s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 validation error for TyposResponse\n",
      "  Invalid JSON: EOF while parsing a string at line 1 column 53074 [type=json_invalid, input_value='{\"text_with_typos\":\"zest... jakichkolwiek objawach', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 84/100 [56:00<36:24, 136.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 validation error for TyposResponse\n",
      "  Invalid JSON: EOF while parsing a string at line 1 column 25021 [type=json_invalid, input_value='{\"text_with_typos\":\"rze ...}  }  }  }  }  }  }  } ', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 85/100 [56:21<25:27, 101.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 validation error for TyposResponse\n",
      "  Invalid JSON: EOF while parsing a string at line 1 column 672 [type=json_invalid, input_value='{\"text_with_typos\":\"ww. ...i jednoznaczny ustalone', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 86/100 [1:00:59<36:03, 154.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 validation error for TyposResponse\n",
      "  Invalid JSON: EOF while parsing a string at line 1 column 45269 [type=json_invalid, input_value='{\"text_with_typos\":\"ntru...o groszy) stanowiącej ', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 93/100 [1:08:45<13:59, 119.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 validation error for TyposResponse\n",
      "  Invalid JSON: EOF while parsing a string at line 1 column 25133 [type=json_invalid, input_value='{\"text_with_typos\":\"\\\\\" ... }  }  }  }  }  }  }  }', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 96/100 [1:14:17<09:08, 137.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 validation error for TyposResponse\n",
      "  Invalid JSON: EOF while parsing a string at line 1 column 45152 [type=json_invalid, input_value='{\"text_with_typos\":\"ego ... orzecznik ZUS, członk', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [1:15:16<00:00, 45.17s/it]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm.trange(100):\n",
    "    prepare_dataset(\"dataset_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [01:55<00:49, 16.52s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm\u001b[38;5;241m.\u001b[39mtrange(\u001b[38;5;241m10\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mprepare_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdataset_test.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 36\u001b[0m, in \u001b[0;36mprepare_dataset\u001b[0;34m(dname)\u001b[0m\n\u001b[1;32m     33\u001b[0m     threads\u001b[38;5;241m.\u001b[39mappend(t)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m threads:\n\u001b[0;32m---> 36\u001b[0m     \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch2.1/lib/python3.12/threading.py:1147\u001b[0m, in \u001b[0;36mThread.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot join current thread\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1147\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait_for_tstate_lock\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1148\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1149\u001b[0m     \u001b[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[1;32m   1150\u001b[0m     \u001b[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[1;32m   1151\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(timeout, \u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[0;32m~/miniconda3/envs/torch2.1/lib/python3.12/threading.py:1167\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1164\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1166\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1167\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mlock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1168\u001b[0m         lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m   1169\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in tqdm.trange(10):\n",
    "    prepare_dataset(\"dataset_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "for i in tqdm.trange(50):\n",
    "    prepare_dataset(\"dataset_train_grpo_sft.csv\", prepare_func=prepare_doc_thinking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [02:25<00:00, 18.20s/it]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm.trange(8):\n",
    "    prepare_dataset(\"dataset_test_grpo_sft.csv\", prepare_func=prepare_doc_thinking)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2.1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
